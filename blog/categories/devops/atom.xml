<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: DevOps | The Raw Bits]]></title>
  <link href="http://hudl.github.com/blog/categories/devops/atom.xml" rel="self"/>
  <link href="http://hudl.github.com/"/>
  <updated>2013-06-25T09:39:12-05:00</updated>
  <id>http://hudl.github.com/</id>
  <author>
    <name><![CDATA[Hudl]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Post-Mortem for Internal Incident on June 13]]></title>
    <link href="http://hudl.github.com/blog/2013/06/20/post-mortem/"/>
    <updated>2013-06-20T00:00:00-05:00</updated>
    <id>http://hudl.github.com/blog/2013/06/20/post-mortem</id>
    <content type="html"><![CDATA[<p><em>We think there are members of the tech community who would appreciate getting our perspective on operational incidents at Hudl. In the spirit of sharing so we can all become better at resolving issues, we present our first public post-mortem.</em></p>

<h2>Summary</h2>

<p>One of our availability zones in AWS (us-east-1) experienced DNS resolution problems, meaning some services within our infrastructure could not talk to other services. We removed traffic from the affected services and monitored the situation. Amazon resolved the issue and we reintroduced traffic to those services.</p>

<p><strong>Time to Discovery</strong> (time from incident origination to our identification of the cause): 11 minutes
<strong>Time to Resolve</strong> (time from identification of the cause to remediation of the incident): 5 minutes</p>

<h2>Technical Details</h2>

<p>Around 17:09 CDT on June 13, some of our servers started logging errors when trying to contact our cache servers. At about 17:15, we were preparing a production deployment when we noticed these errors thanks to a Splunk dashboard. We took note that the errors were coming from one specific availability zone and verified all cache servers were available and responsive. We then accessed two of the servers that were reporting errors and attempted to ping other servers first by DNS, which failed immediately, and then directly by IP, which succeeded. From this, we wagered there was a DNS issue internal to AWS. We watched Twitter for reports to confirm this hypothesis, which happened some minutes later.</p>

<p>About 17:20, we made the call to remove web traffic from these servers using Amazon's Elastic Load Balancer. Even after a couple of minutes, the change did not appear to have taken effect, so we removed each server individually. By 17:25, none of the affected servers were receiving traffic anymore, but they continued to report errors. Over the next twenty minutes, we continued to research the situation, concluding that the driver for the cache servers was continuing to retry the connections and generating the errors, even without web traffic.</p>

<p>At 17:42, AWS acknowledged the problem, and later reported that it was resolved by 17:39. Errors subsided as the affected servers were once again able to contact the cache servers. Around 17:50, we re-enabled traffic and continued to monitor the servers until we were satisfied the situation was resolved.</p>

<p>We have no reason to believe our users were impacted by this event.</p>

<h2>What We Learned</h2>

<p>When we conduct DevOps post-mortems, we want to identify ways to improve our infrastructure to be more fault tolerant, our knowledge to quickly and accurately discover the causes, and our alerts to be fast and with a high signal to noise ratio. That said, we're still careful about what action items we take away. We want to be sure any changes we make will be truly valuable.</p>

<p>The low-impact nature of this incident means we will consider improvements to our fault tolerance in the medium-to-long term rather than right away. One potential improvement we will be looking into is the automatic removal of traffic from servers that are assessed to be unhealthy.</p>

<p>In this case, the primary action item involved creating new alerts. We caught this incident by a happy accident--that someone happened to be looking in the right place at the right time. As a result, we introduced two new Splunk alerts that will bring to our attention similar situations so that our DevOps team can take action right away.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Preparing for Season: Load Testing]]></title>
    <link href="http://hudl.github.com/blog/2012/10/05/load-testing/"/>
    <updated>2012-10-05T00:00:00-05:00</updated>
    <id>http://hudl.github.com/blog/2012/10/05/load-testing</id>
    <content type="html"><![CDATA[<h2>Introduction</h2>

<p>Hudl is fundamentally a technology company, and our area of focus is sports. Since our namesake application is web-based, and most of our partners are football coaches, that presents us with an interesting situation: our usage changes dramatically with the time of the year (and of the week, for that matter). In some ways, that's good. The offseason gives us an opportunity to catch our breath, tackle bigger features, and concentrate on adding more value to our product.</p>

<p>However, since our public launch in 2009, we've expanded our user base significantly each year, and we don't really feel that full impact until the last couple weeks of August when football programs move into full swing. Most other web applications grow at a steady pace, so scaling is something they deal with regularly. They'll likely add some more hardware, optimize their application code, tweak settings, and repeat frequently. Because their site load does not generally recede for longer than a day or so, this strategy will work well.</p>

<p>Hudl's usage is not nearly so regular. Not only is it strongly seasonal, each season brings significantly more users than our application has ever seen before. So how do we prepare? We rely on simulation during the offseason. We work hard to predict our fall numbers and emulate our upcoming usage in order to find bottlenecks and weak links before the real season starts. Simulation is never as good as the real thing, but just like the teams who depend on us, we rely on our preparation to take us successfully through the season.</p>

<h2>Analyzing Current Usage</h2>

<p>Before we can simulate our users' behavior, we have to understand what it is they do. For this, we draw from two main sources of information. The primary is our usage logs. We do extensive logging throughout our application code, and all that data winds up in <a href="http://splunk.com">Splunk</a> where we can search and analyze it. We also use Google Analytics to tell us where users spend most of their time on our site. We look for the HTTP endpoints and services that are most heavily used during our previous season, then factor in recent trends because we've added several new features since December. From here, we'll pick off the most used web requests to emulate. Typically, we draw a line at about 1% or more of the total requests, but it's not an absolute rule because we know from experience that certain services are likely to be costly even if they are not used frequently.</p>

<p>As with all simulation, there are some inaccuracies. Our usage data is good, but it isn't perfect. Even if it were, we wouldn't be able to emulate the usage perfectly, and we leave many of the lesser-used features untested due to resource constraints. And, as I mentioned before, we're relying on numbers from the prior season which is likely to differ from this season's numbers because of new designs and features. We have ways to mitigate these risks, but that's another topic.</p>

<h2>Tools</h2>

<p>Our load testing suite is built on Microsoft's Visual Studio Ultimate load testing framework. Running on a .NET stack, we're already heavily invested in Microsoft's development tools, so it was a natural choice. The starting point for these load tests is recording web tests.</p>

<p><img src="http://static.hudl.com/cms/img/rawbits/vs_webtest.png" title="Visual Studio .webtest screenshot" alt="Visual Studio .webtest screenshot" /></p>

<p>Web tests can make any kind of HTTP request, and the recorder will automatically set appropriate headers for HTML, JSON and SOAP requests. We intentionally keep the .webtest files instead of converting them into C# code because they can be maintained through the GUI, which makes them more accessible for maintenance by even those not intimately acquainted with the suite. To keep the tests in that format required some significant infrastructure in code, though. The framework is delightfully modularized so we can build plugins at all levels of the test to capture, extract, and/or inject data.</p>

<p><div><script src='https://gist.github.com/3841524.js?file=ExtractPublishedClipId.cs'></script>
<noscript><pre><code>using System;
using System.Collections.Generic;
using System.ComponentModel;
using System.Linq;
using System.Xml.Linq;
using Microsoft.VisualStudio.TestTools.WebTesting;

namespace Hudl.WebApp.Tests.TestsCore.ExtractionRules
{
    [DisplayName(&quot;Extract Published Clip ID&quot;)]
    [Description(&quot;For a CreateClip web service request, extracts the newly-created Clip ID value and inserts it into the ID collection specified by the Context parameter name.&quot;)]
    public class ExtractPublishedClipId : ExtractionRule
    {
        private static readonly XNamespace DefaultNamespace;

        static ExtractPublishedClipId()
        {
            DefaultNamespace = &quot;http://tempuri.org/&quot;;
        }

        public override void Extract(object sender, ExtractionEventArgs e)
        {
            var bodyString = e.Response.BodyString;
            var clipId = GetClipId(bodyString);

            if (!clipId.HasValue)
            {
                e.Message = &quot;Extraction of Published Clip ID failed. Result text: &quot; + Environment.NewLine +
                            e.Response.BodyString;
                e.Success = false;
                return;
            }

            var clipIds = e.WebTest.Context[ContextParameterName] as ICollection&lt;long&gt;;
            clipIds.Add(clipId.Value);

            e.Success = true;
        }

        private static long? GetClipId(string bodyString)
        {
            var bodyDoc = XDocument.Parse(bodyString);
            var resultElement = bodyDoc.Descendants(DefaultNamespace + &quot;CreateClipResult&quot;).SingleOrDefault();

            if (resultElement == null)
            {
                return null;
            }

            var createClipResultValue = resultElement.Value;
            var clipId = Convert.ToInt64(createClipResultValue);
            return clipId;
        }
    }
}</code></pre></noscript></div>
</p>

<p>The most important part of our web tests is the seed data. We need it to be as accurate as possible, so we harvest real user data, denormalize it, and insert it into a seed database. We created a tool to do this, of course, and it currently takes about six hours to create this database. Fortunately, we don't need to do it very often as the data is not changed during testing.</p>

<p>Feeding the data into the tests is tricky because the DataSources the framework provides cannot take criteria. When you're emulating a user on Hudl, the data has to be specific to that user or the test is pointless. We leveraged the WebTestPlugin class to create our own datasources that query the seed database for a related set of data and cache it for use during subsequent iterations. It is also lazy loaded. This keeps the memory footprint on the test agents as low as we can keep it, and eases the strain on the seed database (which is located centrally on the load test controller).</p>

<p><div><script src='https://gist.github.com/3841573.js?file=AnnotationsDataSource.cs'></script>
<noscript><pre><code>using System;
using System.Data;
using System.Data.SqlClient;

namespace Hudl.WebApp.Tests.TestsCore.DataSources
{
    public class AnnotationsDataSource : ModifiableQueueBasedDataSource&lt;long&gt;
    {
        private readonly long _userId;

        public AnnotationsDataSource(long userId)
        {
            _userId = userId;
            HasBeenModified = false;
        }

        protected override void LoadItems()
        {
            const string annotationDataQuery = @&quot;SELECT [AnnotationId]
                                                 FROM [AnnotationData] 
                                                 WHERE [UserId] = @UserId&quot;;
            var sqlCommand = new SqlCommand(annotationDataQuery);
            sqlCommand.Parameters.Add(&quot;@UserId&quot;, SqlDbType.BigInt).Value = _userId;

            UsingDataReader(sqlCommand, EnqueueAnnotationData);
        }

        private void EnqueueAnnotationData(SqlDataReader sqlDataReader)
        {
            var annotationId = Convert.ToInt64(sqlDataReader[&quot;AnnotationId&quot;]);

            DataItems.Enqueue(annotationId);
        }

        public override string ToString()
        {
            var value = String.Format(&quot;AnnotationsDataSource: Is loaded: {0}, {1} items, User {2}, Has been modified: {3}&quot;, IsLoaded, DataItems.Count, _userId, HasBeenModified);
            return value;
        }
    }
}</code></pre></noscript></div>
</p>

<p><div><script src='https://gist.github.com/3841578.js?file=AnnotationsDataSourcePlugin.cs'></script>
<noscript><pre><code>using System.ComponentModel;
using Hudl.WebApp.Tests.TestsCore.DataSources;
using Microsoft.VisualStudio.TestTools.WebTesting;

namespace Hudl.WebApp.Tests.TestsCore.Plugins
{
    [DisplayName(&quot;Annotations DataSource&quot;)]
    [Description(&quot;Reads Annotation IDs from the context and assigns values to context parameters.&quot;)]
    public class AnnotationsDataSourcePlugin : WebTestPlugin
    {
        [DisplayName(&quot;DataSource Context Parameter Name&quot;)]
        [Description(&quot;The name of the context parameter which holds the DataSource object.&quot;)]
        [DefaultValue(&quot;AnnotationsDataSource&quot;)]
        public string DataSourceContextParameterName { get; set; }

        [DisplayName(&quot;AnnotationId Context Parameter Name&quot;)]
        [Description(&quot;The name of the context parameter which will be assigned the annotation ID value.&quot;)]
        [DefaultValue(&quot;AnnotationId&quot;)]
        public string AnnotationIdContextParameterName { get; set; }

        public override void PreWebTest(object sender, PreWebTestEventArgs e)
        {
            base.PreWebTest(sender, e);
            var webTextContext = e.WebTest.Context;

            var annotationsDataSource = webTextContext[DataSourceContextParameterName] as IDataSource&lt;long&gt;;

            var annotationId = annotationsDataSource.GetNext();
            webTextContext[AnnotationIdContextParameterName] = annotationId;
        }
    }
}</code></pre></noscript></div>
</p>

<h2>Running in the Cloud</h2>

<p>As you might expect, because Hudl runs on EC2, we also test on and against EC2. We spin up an exact replica of our production environment and enough instances to simulate the number of simultaneous users we want to test. Microsoft recommends each load test agent only run 1000 concurrent users, and we generally stick to that. We need to add one more server to be the controller for the test agents. The controller coordinates the tests, feeds the agents seed data, and collects and aggregates result data. We often run these tests for hours at a time so we can examine the site behavior during and after long periods of stress. When we're through, we can terminate these instances so we only spend money when we're actively testing.</p>

<h2>Wrapping Up</h2>

<p>While the tests are running, we watch site performance and server metrics. Finding and addressing these bottlenecks is a post in itself, but we're especially interested in seeing how our databases perform, where the expensive operations are and if they can be remedied, and how the system reacts when we kill servers. Once the tests have completed, we can critique performance: How many errors did we see, and are they legitimate? Why did these requests take so long? What can we do to improve our average page speed?</p>

<p>The answers to these questions will determine the success of our season and the success of many of our partners' seasons.</p>
]]></content>
  </entry>
  
</feed>
